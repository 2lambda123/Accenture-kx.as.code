require 'json'

current_dir    = File.dirname(File.expand_path(__FILE__))

puts "Running on #{Vagrant::Util::Platform} operating system"

if Vagrant::Util::Platform.windows?
  # Is Windows
  puts "Vagrant launched from Windows."
  vboxExecutable = "C:/Program Files/Oracle/VirtualBox/VBoxManage.exe"
elsif Vagrant::Util::Platform.darwin?
  # Is Mac
  puts "Vagrant launched from Mac."
  vboxExecutable = "/Applications/VirtualBox.app/Contents/MacOS/VBoxManage"
elsif Vagrant::Util::Platform.linux?
  # Is Linux
  puts "Vagrant launched from Linux."
  vboxExecutable = "/usr/bin/vboxmanage"
else
  # Assume WSL for now
  puts "Vagrant launched from other system, maybe WSL? Exiting."
end

# Checking if VirtualBox natnetwork is installed, and configuring it if not
if Vagrant::Util::Platform.windows?
    kxascodeNetworkExists = `bash -c "#{vboxExecutable.shellescape} natnetwork list kxascode | tail -1"`.strip
else
    kxascodeNetworkExists = `bash -c "#{vboxExecutable} natnetwork list kxascode | tail -1"`.strip
end

puts "VirtualBox NAT network found: #{kxascodeNetworkExists}"
if kxascodeNetworkExists == "1 network found"
    puts "VirtualBox already has the KX.AS.CODE NAT network installed. Nothing to do."
elsif kxascodeNetworkExists == "0 networks found"
    puts "VirtualBox does not yet have the KX.AS.CODE NAT network installed. Creating it."
    if Vagrant::Util::Platform.windows?
        `bash -c "#{vboxExecutable.shellescape} natnetwork add --netname kxascode --network '10.100.76.0/24' --enable"`
    else
        `bash -c "#{vboxExecutable} natnetwork add --netname kxascode --network '10.100.76.0/24' --enable"`
    end
end

# Read Profile Config file
file = File.read('profile-config.json')
profile_config_json = JSON.parse(file)

# Read version file
file = File.read('../../versions.json')
kx_version_json = JSON.parse(file)
puts "KX Version JSON #{kx_version_json}"

STANDALONE_MODE = ENV['standaloneMode'] || profile_config_json['config']['standaloneMode']
puts "STANDALONE_MODE: #{STANDALONE_MODE}"

profile_config_local_volumes=profile_config_json['config']['local_volumes']
puts "Profile Config #{profile_config_local_volumes}"

if STANDALONE_MODE != "true"
    # Get needed capacity for GlusterFS volumes disk size
    GLUSTERFS_KUBE_VOLUMES_DISK_SIZE=profile_config_json['config']['glusterFsDiskSize'].to_i + 1
    puts "GlusterFS Disk Size: #{GLUSTERFS_KUBE_VOLUMES_DISK_SIZE}GB"
else
    GLUSTERFS_KUBE_VOLUMES_DISK_SIZE=0
end

# Calculate needed local disk capacity
# Adding 2% and 4% respectively to cover space lost when creating PVs with Sig
NUM_1GB_LOCAL_SIZE=((profile_config_local_volumes['one_gb'].to_f * 1) * 1.04).round
NUM_5GB_LOCAL_SIZE=((profile_config_local_volumes['five_gb'].to_f * 5) * 1.02).round
NUM_10GB_LOCAL_SIZE=((profile_config_local_volumes['ten_gb'].to_f * 10) * 1.02).round
NUM_30GB_LOCAL_SIZE=((profile_config_local_volumes['thirty_gb'].to_f * 30) * 1.02).round
NUM_50GB_LOCAL_SIZE=((profile_config_local_volumes['fifty_gb'].to_f * 50) * 1.02).round

# Calculate disk size needs for requested local volumes configured in profile-config.json
LOCAL_KUBE_VOLUMES_DISK_SIZE=NUM_1GB_LOCAL_SIZE+NUM_5GB_LOCAL_SIZE+NUM_10GB_LOCAL_SIZE+NUM_30GB_LOCAL_SIZE+NUM_50GB_LOCAL_SIZE+1
puts "#{NUM_1GB_LOCAL_SIZE}+#{NUM_5GB_LOCAL_SIZE}+#{NUM_10GB_LOCAL_SIZE}+#{NUM_30GB_LOCAL_SIZE}+#{NUM_50GB_LOCAL_SIZE}+1"
puts "Local Disk Size: #{LOCAL_KUBE_VOLUMES_DISK_SIZE}GB"

# Environment variables will override the profile-config.json file properties. This was added for the Jenkins jobs, so that they can override parameters
ENVIRONMENT_PREFIX = ENV['environmentPrefix'] || profile_config_json['config']['environmentPrefix']
puts "ENVIRONMENT_PREFIX: #{ENVIRONMENT_PREFIX}"
MAIN_NODE_COUNT = ENV['mainNodeCount'] || profile_config_json['config']['vm_properties']['main_node_count']
puts "MAIN_NODE_COUNT: #{MAIN_NODE_COUNT}"
MAIN_ADMIN_NODE_CPU_CORES = ENV['adminMainNodeCpuCores'] || profile_config_json['config']['vm_properties']['main_admin_node_cpu_cores']
puts "MAIN_ADMIN_NODE_CPU_CORES: #{MAIN_ADMIN_NODE_CPU_CORES}"
MAIN_ADMIN_NODE_MEMORY = ENV['adminMainNodeMemory'] || profile_config_json['config']['vm_properties']['main_admin_node_memory']
puts "MAIN_ADMIN_NODE_MEMORY: #{MAIN_ADMIN_NODE_MEMORY}"
MAIN_REPLICA_NODE_CPU_CORES = ENV['replicaMainNodeCpuCores'] || profile_config_json['config']['vm_properties']['main_replica_node_cpu_cores']
puts "MAIN_REPLICA_NODE_CPU_CORES: #{MAIN_REPLICA_NODE_CPU_CORES}"
MAIN_REPLICA_NODE_MEMORY = ENV['replicaMainNodeMemory'] || profile_config_json['config']['vm_properties']['main_replica_node_memory']
puts "MAIN_REPLICA_NODE_MEMORY: #{MAIN_REPLICA_NODE_MEMORY}"
WORKER_NODE_COUNT = ENV['workerNodeCount'] || profile_config_json['config']['vm_properties']['worker_node_count']
puts "WORKER_NODE_COUNT: #{WORKER_NODE_COUNT}"
WORKER_NODE_CPU_CORES = ENV['workerNodeCpuCores'] || profile_config_json['config']['vm_properties']['worker_node_cpu_cores']
puts "WORKER_NODE_CPU_CORES: #{WORKER_NODE_CPU_CORES}"
WORKER_NODE_MEMORY = ENV['WorkerNodeMemory'] || profile_config_json['config']['vm_properties']['worker_node_memory']
puts "WORKER_NODE_MEMORY: #{WORKER_NODE_MEMORY}"
THREE_D_ACCELERATION = ENV['threedAcceleration'] || profile_config_json['config']['vm_properties']['3d_acceleration']
puts "WORKER_NODE_MEMORY: #{THREE_D_ACCELERATION}"
MAIN_BOX_VERSION = ENV['mainBoxVersion'] || kx_version_json['kxascode']
puts "MAIN_BOX_VERSION: #{MAIN_BOX_VERSION}"
NODE_BOX_VERSION = ENV['nodeBoxVersion'] || kx_version_json['kxascode']
puts "NODE_BOX_VERSION: #{NODE_BOX_VERSION}"

HASH = ""
if File.exist?(".vmCredentialsFile")
    HASH = ENV['hash']
    if HASH.nil? || HASH.empty?
        if File.exist?(".hash")
            puts "Found .hash file .Extracting the hash value for decrypting secrets in VM"
            HASH = file = File.read('.hash')
        else
            puts "WARN: Both .hash file and hash environment variable don't exist. This will lead to corrupt failed decryption inside the VM"
        end
    else
        puts "Using environment variable hash for decrypting secrets in VM"
    end
else
    puts "No .vmCredentials file found in profile folder. No credentials to upload and decrypt inside the VM"
end

KX_MAIN_BOX_LOCATION = ENV['kxMainBoxLocation'] || "base-vm/boxes/virtualbox-#{MAIN_BOX_VERSION}/kx-main-#{MAIN_BOX_VERSION}.box"
puts "KX_MAIN_BOX_LOCATION: #{KX_MAIN_BOX_LOCATION}"
KX_NODE_BOX_LOCATION = ENV['kxNodeBoxLocation'] || "base-vm/boxes/virtualbox-#{NODE_BOX_VERSION}/kx-node-#{NODE_BOX_VERSION}.box"
puts "KX_NODE_BOX_LOCATION: #{KX_NODE_BOX_LOCATION}"

WORKSPACE_HOME ||= :"../.."

if File.exist?("#{WORKSPACE_HOME}/#{KX_MAIN_BOX_LOCATION}")
    KX_MAIN_BOX_URL = "file://#{WORKSPACE_HOME}/#{KX_MAIN_BOX_LOCATION}"
    puts "Found local box #{KX_MAIN_BOX_URL}, using that instead of cloud"
else
    KX_MAIN_BOX_URL = "https://app.vagrantup.com/kxascode/boxes/kx-main"
    puts "Did not find local box #{KX_MAIN_BOX_LOCATION}, downloading box from cloud"
end

if File.exist?("#{WORKSPACE_HOME}/#{KX_NODE_BOX_LOCATION}")
    KX_NODE_BOX_URL = "file://#{WORKSPACE_HOME}/#{KX_NODE_BOX_LOCATION}"
    puts "Found local box #{KX_NODE_BOX_URL}, using that instead of cloud"
else
    KX_NODE_BOX_URL = "https://app.vagrantup.com/kxascode/boxes/kx-node"
    puts "Did not find local box #{KX_NODE_BOX_LOCATION}, downloading box from cloud"
end

if (MAIN_NODE_COUNT - 1) < 1
  MAIN_REPLICA_NODE_COUNT = 0
  puts "MAIN_REPLICA_NODE_COUNT < 1 -> #{MAIN_REPLICA_NODE_COUNT} replica main nodes will be provisioned"
else
  MAIN_REPLICA_NODE_COUNT = MAIN_NODE_COUNT - 1
  puts "MAIN_REPLICA_NODE_COUNT > 1 -> #{MAIN_REPLICA_NODE_COUNT} replica main nodes will be provisioned"
end

begin
  NAT_MAIN_GUEST_IP_ADDRESS = profile_config_json['config']['staticNetworkSetup']['baseFixedIpAddresses']['kx-main1']
rescue
  NAT_MAIN_GUEST_IP_ADDRESS = "0.0.0.0"
end
puts "NAT_MAIN_GUEST_IP_ADDRESS: #{NAT_MAIN_GUEST_IP_ADDRESS}"

# Path for current Jenkins solution
WORKSPACE_HOME = File.dirname(File.expand_path('../..', __FILE__))

Vagrant.configure("2") do |config|
  config.vm.define "kx-main1", primary: true do |subconfig|
    subconfig.vm.box = "kxascode/kx-main"
    if KX_MAIN_BOX_URL.start_with?("https://app.vagrantup.com/kxascode")
        subconfig.vm.box_version = "#{MAIN_BOX_VERSION}"
    end
    subconfig.vm.hostname = "kx-main1"
    subconfig.vm.network :forwarded_port, guest: 22, host: 2222, id: "ssh", disabled: true
    subconfig.vm.network :forwarded_port, guest: 22, host: 2230, id: "ssh-kx-main", auto_correct: true
    subconfig.vm.network :forwarded_port, guest_ip: "#{NAT_MAIN_GUEST_IP_ADDRESS}", guest: 5672, host_ip: "127.0.0.1", host: 5672, id: "rabbitmq"
    subconfig.vm.network :forwarded_port, guest_ip: "#{NAT_MAIN_GUEST_IP_ADDRESS}", guest: 15672, host_ip: "127.0.0.1", host: 15672, id: "rabbitmq-api"
    subconfig.vm.network :forwarded_port, guest_ip: "#{NAT_MAIN_GUEST_IP_ADDRESS}", guest: 3000, host_ip: "127.0.0.1", host: 8080, id: "kx-portal", auto_correct: true
    subconfig.vm.network :forwarded_port, guest_ip: "#{NAT_MAIN_GUEST_IP_ADDRESS}", guest: 443, host_ip: "127.0.0.1", host: 443, id: "k8s-ingress", auto_correct: true
    subconfig.vm.network :forwarded_port, guest_ip: "#{NAT_MAIN_GUEST_IP_ADDRESS}", guest: 8043, host_ip: "127.0.0.1", host: 8043, id: "guacamole-remote-desktop", auto_correct: true
    subconfig.vm.network :forwarded_port, guest_ip: "#{NAT_MAIN_GUEST_IP_ADDRESS}", guest: 5901, host_ip: "127.0.0.1", host: 5901, id: "tigervnc-remote-desktop", auto_correct: true
    subconfig.vm.network :forwarded_port, guest_ip: "#{NAT_MAIN_GUEST_IP_ADDRESS}", guest: 4000, host_ip: "127.0.0.1", host: 4000, id: "nomachine-remote-desktop", auto_correct: true
    subconfig.vm.box_url = "#{KX_MAIN_BOX_URL}"
    subconfig.vm.provision "shell", inline: "hostname -I && hostname -I | awk {'print $1'} | tr -d ' \\t\\n\\r' | sudo tee /vagrant/kx.as.code_main-ip-address"
    subconfig.vm.provision "shell", inline: "for i in {1..5}; do echo \"Waiting for /vagrant ... [\${i}\" of 5]; if [ -d /vagrant ]; then sudo cp -v -f /vagrant/*.json /usr/share/kx.as.code/workspace; break; else echo \"/vagrant not yet not available\"; sleep 5; fi; done"
    subconfig.vm.provision "shell", inline: "sudo cp -f /vagrant/.vmCredentialsFile /usr/share/kx.as.code/.config/ 2>/dev/null || true"
    subconfig.vm.provision "shell", inline: "sudo mkdir -p /usr/share/kx.as.code/workspace/custom-images"
    subconfig.vm.provision "shell", inline: "sudo cp -v -f /vagrant/avatar.{jpg,png} /vagrant/background.{jpg,png} /vagrant/boot.{jpg,png} /vagrant/conky_logo.{jpg,png} /vagrant/logo_icon.{jpg,png} /usr/share/kx.as.code/workspace/custom-images 2>/dev/null || true"
    subconfig.vm.provision "shell", inline: "jq '. + { \"state\": { \"networking_configuration_status\": \"todo\", \"kx_main1_ip_address\": \"'$(cat /vagrant/kx.as.code_main-ip-address)'\", \"provisioned_disks\": { \"local_storage_disk_size\": #{LOCAL_KUBE_VOLUMES_DISK_SIZE}, \"network_storage_disk_size\": #{GLUSTERFS_KUBE_VOLUMES_DISK_SIZE} } } }' /usr/share/kx.as.code/workspace/profile-config.json >/tmp/profile-config.json && mv /tmp/profile-config.json /usr/share/kx.as.code/workspace/profile-config.json"
    subconfig.vm.provision "shell", inline: "cat /usr/share/kx.as.code/workspace/profile-config.json | jq '.'"
    subconfig.vm.provision "shell", inline: "cat /usr/share/kx.as.code/workspace/users.json | jq '.'"
    subconfig.vm.provision "shell", inline: "cat /usr/share/kx.as.code/workspace/customVariables.json | jq '.'"
    subconfig.vm.provision "shell", inline: "cat /usr/share/kx.as.code/workspace/actionQueues.json | jq '.'"
    subconfig.vm.provision "shell", inline: 'echo $1 | sudo tee /var/tmp/.hash && sudo chmod 400 /var/tmp/.hash', :args => "#{HASH}"
    subconfig.vm.provision "shell", inline: 'echo -e "$(date "+%Y-%m-%d_%H%M%S") | KX-Main VM created by Vagrant" | sudo tee /usr/share/kx.as.code/workspace/gogogo'
    subconfig.trigger.after :destroy do
          warn = "Destroying kx-main1 disk and IP address file"
          run = {
            inline: <<-SHELL
                rm -f kx.as.code_main-ip-address
                rm -f kx-main1-local-k8s-storage.vdi
                rm -f kx-main1-glusterfs-k8s-storage.vdi
                SHELL
                }
    end
    subconfig.vm.provider "virtualbox" do |v|

      kx_main1_local_k8s_storage = "#{current_dir}/kx-main1-local-k8s-storage.vdi"
      if ARGV[0] == "up" && ! File.exist?(kx_main1_local_k8s_storage)
        v.customize [
          'createhd',
          '--filename', kx_main1_local_k8s_storage,
          '--format', 'VDI',
           '--size', LOCAL_KUBE_VOLUMES_DISK_SIZE.to_i * 1024
        ]

        v.customize [
          'storageattach', :id,
          '--storagectl', 'SATA Controller',
          '--port', 1, '--device', 0,
          '--type', 'hdd', '--medium',
          kx_main1_local_k8s_storage
        ]
      end

      if STANDALONE_MODE != "true"
          kx_main1_glusterfs_k8s_storage="#{current_dir}/kx-main1-glusterfs-k8s-storage.vdi"
          if ARGV[0] == "up" && ! File.exist?(kx_main1_glusterfs_k8s_storage)
                v.customize [
                  'createhd',
                  '--filename', kx_main1_glusterfs_k8s_storage,
                  '--format', 'VDI',
                   '--size', GLUSTERFS_KUBE_VOLUMES_DISK_SIZE.to_i * 1024
                ]

                v.customize [
                  'storageattach', :id,
                  '--storagectl', 'SATA Controller',
                  '--port', 2, '--device', 0,
                  '--type', 'hdd', '--medium',
                  kx_main1_glusterfs_k8s_storage
                ]
          end
      end

      v.name = "kx.as.code-#{ENVIRONMENT_PREFIX}-main1-#{MAIN_BOX_VERSION}"
      v.customize ["modifyvm", :id, "--memory", "#{MAIN_ADMIN_NODE_MEMORY}"]
      v.customize ["modifyvm", :id, "--cpus", "#{MAIN_ADMIN_NODE_CPU_CORES}"]
      v.customize ["modifyvm", :id, "--graphicscontroller", "vmsvga"]
      v.customize ["modifyvm", :id, "--accelerate3d", "#{THREE_D_ACCELERATION}"]
      v.customize ["modifyvm", :id, "--vram", "128"]
      v.customize ["setextradata", :id, "CustomVideoMode1", "1920x1200x32"]
      v.customize ["modifyvm", :id, "--nic1", "nat"]
      v.customize ["modifyvm", :id, "--nic2", "natnetwork","--natnetwork1","kxascode"]
    end
  end

    (2..MAIN_NODE_COUNT).each do |i|
      config.vm.define "kx-main#{i}", primary: false, autostart: false do |subconfig|
        subconfig.vm.box = "kxascode/kx-node"
        if KX_NODE_BOX_URL.start_with?("https://app.vagrantup.com/kxascode")
            subconfig.vm.box_version = "#{NODE_BOX_VERSION}"
        end
        subconfig.vm.hostname = "kx-main#{i}"
        subconfig.vm.network :forwarded_port, guest: 22, host: 2222, id: "ssh", disabled: true
        subconfig.vm.network :forwarded_port, guest: 22, host: "224#{i}", id: "ssh-kx-main#{i}", auto_correct: true
        subconfig.vm.box_url = "#{KX_NODE_BOX_URL}"
        subconfig.vm.provision "shell", inline: "while [ ! -f /vagrant/kx.as.code_main-ip-address ]; do echo \"Waiting for kx.as.code_main-ip-address\" && sleep 15; done; cp /vagrant/kx.as.code_main-ip-address /var/tmp/"
        subconfig.vm.provision "shell", inline: "for i in {1..5}; do echo \"Waiting for /vagrant ... [\${i}\" of 5]; if [ -d /vagrant ]; then sudo cp -v -f /vagrant/profile-config.json /usr/share/kx.as.code/workspace; break; else echo \"/vagrant not yet not available\"; sleep 5; fi; done"
        subconfig.vm.provision "shell", inline: "jq '. + { \"state\": { \"networking_configuration_status\": \"todo\", \"kx_main1_ip_address\": \"'$(cat /vagrant/kx.as.code_main-ip-address)'\", \"provisioned_disks\": { \"local_storage_disk_size\": #{LOCAL_KUBE_VOLUMES_DISK_SIZE}, \"network_storage_disk_size\": #{GLUSTERFS_KUBE_VOLUMES_DISK_SIZE} } } }' /usr/share/kx.as.code/workspace/profile-config.json >/tmp/profile-config.json && mv /tmp/profile-config.json /usr/share/kx.as.code/workspace/profile-config.json"
        subconfig.vm.provision "shell", inline: "cat /usr/share/kx.as.code/workspace/profile-config.json | jq '.'"
        subconfig.vm.provision "shell", inline: 'echo -e "$(date "+%Y-%m-%d_%H%M%S") | KX-Main VM created by Vagrant" | sudo tee /usr/share/kx.as.code/workspace/gogogo'
        subconfig.trigger.after :destroy do
              warn = "Destroying kx-main#{i} VM's disks"
              run = {
                inline: <<-SHELL
                    rm -f kx-main#{i}-local-k8s-storage.vdi
                    SHELL
                    }
        end
        subconfig.vm.provider "virtualbox" do |v|

          kx_main_local_k8s_storage = "#{current_dir}/kx-main#{i}-local-k8s-storage.vdi"
          if ARGV[0] == "up" && ! File.exist?(kx_main_local_k8s_storage)
            v.customize [
              'createhd',
              '--filename', kx_main_local_k8s_storage,
              '--format', 'VDI',
               '--size', LOCAL_KUBE_VOLUMES_DISK_SIZE * 1024
            ]

            v.customize [
              'storageattach', :id,
              '--storagectl', 'SATA Controller',
              '--port', 1, '--device', 0,
              '--type', 'hdd', '--medium',
              kx_main_local_k8s_storage
            ]
          end

          v.name = "kx.as.code-#{ENVIRONMENT_PREFIX}-main#{i}-#{NODE_BOX_VERSION}"
          v.customize ["modifyvm", :id, "--memory", "#{MAIN_REPLICA_NODE_MEMORY}"]
          v.customize ["modifyvm", :id, "--cpus", "#{MAIN_REPLICA_NODE_CPU_CORES}"]
          v.customize ["modifyvm", :id, "--nic1", "nat"]
          v.customize ["modifyvm", :id, "--nic2", "natnetwork","--natnetwork1","kxascode"]
        end
      end
    end


    (1..WORKER_NODE_COUNT).each do |i|
      config.vm.define "kx-worker#{i}" do |subconfig|
        subconfig.vm.box = "kxascode/kx-node"
        if KX_NODE_BOX_URL.start_with?("https://app.vagrantup.com/kxascode")
            subconfig.vm.box_version = "#{NODE_BOX_VERSION}"
        end
        subconfig.vm.hostname = "kx-worker#{i}"
        subconfig.vm.network :forwarded_port, guest: 22, host: 2222, id: "ssh", disabled: true
        subconfig.vm.network :forwarded_port, guest: 22, host: "223#{i}", id: "ssh-kx-worker#{i}", auto_correct: true
        subconfig.vm.box_url = "#{KX_NODE_BOX_URL}"
        subconfig.vm.provision "shell", inline: "while [ ! -f /vagrant/kx.as.code_main-ip-address ]; do echo \"Waiting for kx.as.code_main-ip-address\" && sleep 15; done; cp /vagrant/kx.as.code_main-ip-address /var/tmp/"
        subconfig.vm.provision "shell", inline: "for i in {1..5}; do echo \"Waiting for /vagrant ... [\${i}\" of 5]; if [ -d /vagrant ]; then sudo cp -v -f /vagrant/profile-config.json /usr/share/kx.as.code/workspace; break; else echo \"/vagrant not yet not available\"; sleep 5; fi; done"
        subconfig.vm.provision "shell", inline: "jq '. + { \"state\": { \"networking_configuration_status\": \"todo\", \"kx_main1_ip_address\": \"'$(cat /vagrant/kx.as.code_main-ip-address)'\", \"provisioned_disks\": { \"local_storage_disk_size\": #{LOCAL_KUBE_VOLUMES_DISK_SIZE}, \"network_storage_disk_size\": #{GLUSTERFS_KUBE_VOLUMES_DISK_SIZE} } } }' /usr/share/kx.as.code/workspace/profile-config.json >/tmp/profile-config.json && mv /tmp/profile-config.json /usr/share/kx.as.code/workspace/profile-config.json"
        subconfig.vm.provision "shell", inline: "cat /usr/share/kx.as.code/workspace/profile-config.json | jq '.'"
        subconfig.vm.provision "shell", inline: 'echo -e "$(date "+%Y-%m-%d_%H%M%S") | KX-Worker VM created by Vagrant" | sudo tee /usr/share/kx.as.code/workspace/gogogo'
        subconfig.trigger.after :destroy do
              warn = "Destroying kx-worker#{i} VM's disks"
              run = {
                inline: <<-SHELL
                    rm -f kx-worker#{i}-local-k8s-storage.vdi
                    SHELL
                    }
        end
        subconfig.vm.provider "virtualbox" do |v|

          kx_worker_local_k8s_storage = "#{current_dir}/kx-worker#{i}-local-k8s-storage.vdi"
          if ARGV[0] == "up" && ! File.exist?(kx_worker_local_k8s_storage)
            v.customize [
              'createhd',
              '--filename', kx_worker_local_k8s_storage,
              '--format', 'VDI',
               '--size', LOCAL_KUBE_VOLUMES_DISK_SIZE * 1024
            ]

            v.customize [
              'storageattach', :id,
              '--storagectl', 'SATA Controller',
              '--port', 1, '--device', 0,
              '--type', 'hdd', '--medium',
              kx_worker_local_k8s_storage
            ]
          end

          v.name = "kx.as.code-#{ENVIRONMENT_PREFIX}-worker#{i}-#{NODE_BOX_VERSION}"
          v.customize ["modifyvm", :id, "--memory", "#{WORKER_NODE_MEMORY}"]
          v.customize ["modifyvm", :id, "--cpus", "#{WORKER_NODE_CPU_CORES}"]
          v.customize ["modifyvm", :id, "--nic1", "nat"]
          v.customize ["modifyvm", :id, "--nic2", "natnetwork","--natnetwork1","kxascode"]
        end
      end
    end

end
