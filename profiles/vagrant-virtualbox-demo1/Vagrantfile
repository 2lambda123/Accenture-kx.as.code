require 'json'

current_dir    = File.dirname(File.expand_path(__FILE__))

if Vagrant::Util::Platform.windows?
  # Is Windows
  puts "Vagrant launched from windows."
elsif Vagrant::Util::Platform.darwin?
  # Is Mac
  puts "Vagrant launched from mac."
else
  # Assume WSL for now
  puts "Vagrant launched from other system, maybe WSL?"
end

# Read Profile Config file
file = File.read('profile-config.json')
profile_config_json = JSON.parse(file)

# Read version file
file = File.read('../../version.json')
kx_version_json = JSON.parse(file)
puts "KX Version JSON #{kx_version_json}"

profile_config_local_volumes=profile_config_json['config']['local_volumes']
puts "Profile Config #{profile_config_local_volumes}"

# Get needed capacity for GlusterFS volumes disk size
GLUSTERFS_KUBE_VOLUMES_DISK_SIZE=profile_config_json['config']['glusterFsDiskSize']

# Calculate needed local disk capacity
NUM_1GB_LOCAL_SIZE=profile_config_local_volumes['one_gb'].to_i * 1
NUM_5GB_LOCAL_SIZE=profile_config_local_volumes['five_gb'].to_i * 5
NUM_10GB_LOCAL_SIZE=profile_config_local_volumes['ten_gb'].to_i * 10
NUM_30GB_LOCAL_SIZE=profile_config_local_volumes['thirty_gb'].to_i * 30
NUM_50GB_LOCAL_SIZE=profile_config_local_volumes['fifty_gb'].to_i * 50

# Calculate disk size needs for requested local volumes configured in profile-config.json
LOCAL_KUBE_VOLUMES_DISK_SIZE=NUM_1GB_LOCAL_SIZE+NUM_5GB_LOCAL_SIZE+NUM_10GB_LOCAL_SIZE+NUM_30GB_LOCAL_SIZE+NUM_50GB_LOCAL_SIZE+1

puts "Local Disk Size: #{LOCAL_KUBE_VOLUMES_DISK_SIZE}GB"
puts "GlusterFS Disk Size: #{GLUSTERFS_KUBE_VOLUMES_DISK_SIZE}GB"

# Environment variables will override the profile-config.json file properties. This was added for the Jenkins jobs, so that they can override parameters
ENVIRONMENT_PREFIX = ENV['environmentPrefix'] || profile_config_json['config']['vm_properties']['environment_prefix']
puts "ENVIRONMENT_PREFIX: #{ENVIRONMENT_PREFIX}"
MAIN_NODE_COUNT = ENV['mainNodeCount'] || profile_config_json['config']['vm_properties']['main_node_count']
puts "MAIN_NODE_COUNT: #{MAIN_NODE_COUNT}"
ADMIN_MAIN_NODE_CPU_CORES = ENV['adminMainNodeCpuCores'] || profile_config_json['config']['vm_properties']['admin_main_node_cpu_cores']
puts "ADMIN_MAIN_NODE_CPU_CORES: #{ADMIN_MAIN_NODE_CPU_CORES}"
ADMIN_MAIN_NODE_MEMORY = ENV['adminMainNodeMemory'] || profile_config_json['config']['vm_properties']['admin_main_node_memory']
puts "ADMIN_MAIN_NODE_MEMORY: #{ADMIN_MAIN_NODE_MEMORY}"
REPLICA_MAIN_NODE_CPU_CORES = ENV['replicaMainNodeCpuCores'] || profile_config_json['config']['vm_properties']['replica_main_node_cpu_cores']
puts "REPLICA_MAIN_NODE_CPU_CORES: #{REPLICA_MAIN_NODE_CPU_CORES}"
REPLICA_MAIN_NODE_MEMORY = ENV['replicaMainNodeMemory'] || profile_config_json['config']['vm_properties']['replica_main_node_memory']
puts "REPLICA_MAIN_NODE_MEMORY: #{REPLICA_MAIN_NODE_MEMORY}"
WORKER_NODE_COUNT = ENV['workerNodeCount'] || profile_config_json['config']['vm_properties']['worker_node_count']
puts "WORKER_NODE_COUNT: #{WORKER_NODE_COUNT}"
WORKER_NODE_CPU_CORES = ENV['workerNodeCpuCores'] || profile_config_json['config']['vm_properties']['worker_node_cpu_cores']
puts "WORKER_NODE_CPU_CORES: #{WORKER_NODE_CPU_CORES}"
WORKER_NODE_MEMORY = ENV['WorkerNodeMemory'] || profile_config_json['config']['vm_properties']['worker_node_memory']
puts "WORKER_NODE_MEMORY: #{WORKER_NODE_MEMORY}"
THREE_D_ACCELERATION = ENV['threedAcceleration'] || profile_config_json['config']['vm_properties']['3d_acceleration']
puts "WORKER_NODE_MEMORY: #{THREE_D_ACCELERATION}"
DOCKERHUB_USER = ENV['dockerHubUser'] || profile_config_json['config']['docker']['dockerhub_username']
puts "DOCKERHUB_USER: #{DOCKERHUB_USER}"
DOCKERHUB_EMAIL = ENV['dockerHubEmail'] || profile_config_json['config']['docker']['dockerhub_email']
puts "DOCKERHUB_EMAIL: #{DOCKERHUB_EMAIL}"
DOCKERHUB_PASSWORD = ENV['DockerHubPassword'] || profile_config_json['config']['docker']['dockerhub_password']
puts "DOCKERHUB_PASSWORD: #{DOCKERHUB_PASSWORD}"
BOX_VERSION = ENV['boxVersion'] || kx_version_json['version']
puts "BOX_VERSION: #{BOX_VERSION}"
KX_MAIN_BOX_LOCATION = ENV['kxMainBoxLocation'] || profile_config_json['config']['vm_properties']['kx_main_box_location']
puts "KX_MAIN_BOX_LOCATION: #{KX_MAIN_BOX_LOCATION}"
KX_NODE_BOX_LOCATION = ENV['kxWorkerBoxLocation'] || profile_config_json['config']['vm_properties']['kx_node_box_location']
puts "KX_NODE_BOX_LOCATION: #{KX_NODE_BOX_LOCATION}"

if (MAIN_NODE_COUNT - 1) < 1
  REPLICA_MAIN_NODE_COUNT = 0
  puts "REPLICA_MAIN_NODE_COUNT < 1 -> #{REPLICA_MAIN_NODE_COUNT} replica main nodes will be provisioned"
else
  REPLICA_MAIN_NODE_COUNT = MAIN_NODE_COUNT - 1
  puts "REPLICA_MAIN_NODE_COUNT > 1 -> #{REPLICA_MAIN_NODE_COUNT} replica main nodes will be provisioned"
end

# Path for current Jenkins solution
WORKSPACE_HOME = File.dirname(File.expand_path('../../..', __FILE__))

Vagrant.configure("2") do |config|
  config.vm.define "kx.as.code-main1", primary: true do |subconfig|
    subconfig.vm.box = "kx.as.code-main1"
    subconfig.vm.hostname = "kx-main1"
    subconfig.vm.network :forwarded_port, guest: 22, host: 2222, id: "ssh", disabled: true
    subconfig.vm.network :forwarded_port, guest: 22, host: 2230, id: "ssh-kx-main", auto_correct: true
    subconfig.vm.box_url = "file://#{WORKSPACE_HOME}/#{KX_MAIN_BOX_LOCATION}"
    subconfig.vm.provision "file", source: "profile-config.json", destination: "/var/tmp/profile-config.json"
    subconfig.vm.provision "file", source: "users.json", destination: "/var/tmp/users.json"
    Dir[File.dirname(__FILE__) + '/aq*.json'].each do |file|
        file_name = File.basename(file)
        subconfig.vm.provision "file", source: file_name, destination: "/var/tmp/" + file_name
    end
    subconfig.vm.provision "shell", inline: "hostname -I | awk {'print $1'} | tr -d ' \\t\\n\\r' | sudo tee /vagrant/kx.as.code_main-ip-address"
    subconfig.vm.provision "shell", inline: 'sudo mv /var/tmp/aq*.json /usr/share/kx.as.code/workspace/'
    subconfig.vm.provision "shell", inline: 'sudo mv /var/tmp/users.json /usr/share/kx.as.code/workspace/'
    subconfig.vm.provision "shell", inline: "sudo mv /var/tmp/profile-config.json /usr/share/kx.as.code/workspace/"
    subconfig.vm.provision "shell", inline: "cat /usr/share/kx.as.code/workspace/profile-config.json | jq '.'"
    subconfig.vm.provision "shell", inline: "cat /usr/share/kx.as.code/workspace/users.json | jq '.'"
    subconfig.vm.provision "shell", inline: 'echo -e "$(date "+%Y-%m-%d_%H%M%S") | KX-Main VM created by Vagrant" | sudo tee /usr/share/kx.as.code/workspace/gogogo'
    subconfig.trigger.after :destroy do |trigger|
    trigger.warn = "Destroying VM's disks"
        trigger.run = { :inline => "bash -c 'rm -f kx.as.code_main-ip-address kx-main1-local-k8s-storage.vdi kx-main1-glusterfs-k8s-storage.vdi'" }
    end
    subconfig.vm.provision :shell do |s|
      s.inline = "echo -e \"DOCKERHUB_USER=#{DOCKERHUB_USER}\nDOCKERHUB_EMAIL=#{DOCKERHUB_EMAIL}\nDOCKERHUB_PASSWORD=#{DOCKERHUB_PASSWORD}\" | sudo tee /var/tmp/.textfile"
    end
    subconfig.vm.provider "virtualbox" do |v|

      kx_main_local_k8s_storage = "#{current_dir}/kx-main1-local-k8s-storage.vdi"
      if ARGV[0] == "up" && ! File.exist?(kx_main_local_k8s_storage)
        v.customize [
          'createhd',
          '--filename', kx_main_local_k8s_storage,
          '--format', 'VDI',
           '--size', LOCAL_KUBE_VOLUMES_DISK_SIZE.to_i * 1024
        ]

        v.customize [
          'storageattach', :id,
          '--storagectl', 'SATA Controller',
          '--port', 1, '--device', 0,
          '--type', 'hdd', '--medium',
          kx_main_local_k8s_storage
        ]
      end

      kx_main_glusterfs_k8s_storage="#{current_dir}/kx-main1-glusterfs-k8s-storage.vdi"
      if ARGV[0] == "up" && ! File.exist?(kx_main_glusterfs_k8s_storage)
            v.customize [
              'createhd',
              '--filename', kx_main_glusterfs_k8s_storage,
              '--format', 'VDI',
               '--size', GLUSTERFS_KUBE_VOLUMES_DISK_SIZE.to_i * 1024
            ]

            v.customize [
              'storageattach', :id,
              '--storagectl', 'SATA Controller',
              '--port', 2, '--device', 0,
              '--type', 'hdd', '--medium',
              kx_main_glusterfs_k8s_storage
            ]
      end

      v.name = "kx.as.code-#{ENVIRONMENT_PREFIX}-main1-#{BOX_VERSION}"
      v.customize ["modifyvm", :id, "--memory", "#{MAIN_NODE_MEMORY}"]
      v.customize ["modifyvm", :id, "--cpus", "#{MAIN_NODE_CPU_CORES}"]
      v.customize ["modifyvm", :id, "--graphicscontroller", "vmsvga"]
      v.customize ["modifyvm", :id, "--accelerate3d", "#{THREE_D_ACCELERATION}"]
      v.customize ["modifyvm", :id, "--vram", "128"]
      v.customize ["setextradata", :id, "CustomVideoMode1", "1920x1200x32"]
      v.customize ["modifyvm", :id, "--nic1", "nat"]
      v.customize ["modifyvm", :id, "--nic2", "natnetwork","--natnetwork1","kxascode"]
    end
  end

    (2..MAIN_NODE_COUNT).each do |i|
      config.vm.define "kx.as.code-main#{i}" do |subconfig|
        subconfig.vm.box = "kx.as.code-main"
        subconfig.vm.hostname = "kx-main#{i}"
        subconfig.vm.network :forwarded_port, guest: 22, host: 2222, id: "ssh", disabled: true
        subconfig.vm.network :forwarded_port, guest: 22, host: "224#{i}", id: "ssh-kx-main#{i}", auto_correct: true
        subconfig.vm.box_url = "file://#{WORKSPACE_HOME}/#{KX_NODE_BOX_LOCATION}"
        subconfig.vm.provision "file", source: "kx.as.code_main-ip-address", destination: "/var/tmp/kx.as.code_main-ip-address"
        subconfig.vm.provision "file", source: "profile-config.json", destination: "/var/tmp/profile-config.json"
        subconfig.vm.provision "shell", inline: "sudo mv /var/tmp/profile-config.json /usr/share/kx.as.code/workspace/"
        subconfig.vm.provision "shell", inline: "cat /usr/share/kx.as.code/workspace/profile-config.json | jq '.'"
        subconfig.vm.provision "shell", inline: 'echo -e "$(date "+%Y-%m-%d_%H%M%S") | KX-Main VM created by Vagrant" | sudo tee /usr/share/kx.as.code/workspace/gogogo'
        subconfig.trigger.after :destroy do |trigger|
          trigger.warn = "Destroying VM's disks"
          trigger.run = { :inline => "bash -c 'rm -f kx-main#{i}-local-k8s-storage.vdi'" }
        end
        subconfig.vm.provider "virtualbox" do |v|

          kx_main_local_k8s_storage = "#{current_dir}/kx-main#{i}-local-k8s-storage.vdi"
          if ARGV[0] == "up" && ! File.exist?(kx_main_local_k8s_storage)
            v.customize [
              'createhd',
              '--filename', kx_main_local_k8s_storage,
              '--format', 'VDI',
               '--size', LOCAL_KUBE_VOLUMES_DISK_SIZE * 1024
            ]

            v.customize [
              'storageattach', :id,
              '--storagectl', 'SATA Controller',
              '--port', 1, '--device', 0,
              '--type', 'hdd', '--medium',
              kx_main_local_k8s_storage
            ]
          end

          v.name = "kx.as.code-#{ENVIRONMENT_PREFIX}-main#{i}-#{BOX_VERSION}"
          v.customize ["modifyvm", :id, "--memory", "#{REPLICA_MAIN_NODE_MEMORY}"]
          v.customize ["modifyvm", :id, "--cpus", "#{REPLICA_MAIN_NODE_CPU_CORES}"]
          v.customize ["modifyvm", :id, "--nic1", "nat"]
          v.customize ["modifyvm", :id, "--nic2", "natnetwork","--natnetwork1","kxascode"]
        end
      end
    end


    (1..WORKER_NODE_COUNT).each do |i|
      config.vm.define "kx.as.code-worker#{i}" do |subconfig|
        subconfig.vm.box = "kx.as.code-worker"
        subconfig.vm.hostname = "kx-worker#{i}"
        subconfig.vm.network :forwarded_port, guest: 22, host: 2222, id: "ssh", disabled: true
        subconfig.vm.network :forwarded_port, guest: 22, host: "223#{i}", id: "ssh-kx-worker#{i}", auto_correct: true
        subconfig.vm.box_url = "file://#{WORKSPACE_HOME}/#{KX_NODE_BOX_LOCATION}"
        subconfig.vm.provision "file", source: "kx.as.code_main-ip-address", destination: "/var/tmp/kx.as.code_main-ip-address"
        subconfig.vm.provision "file", source: "profile-config.json", destination: "/var/tmp/profile-config.json"
        subconfig.vm.provision "shell", inline: "sudo mv /var/tmp/profile-config.json /usr/share/kx.as.code/workspace/"
        subconfig.vm.provision "shell", inline: "cat /usr/share/kx.as.code/workspace/profile-config.json | jq '.'"
        subconfig.vm.provision "shell", inline: 'echo -e "$(date "+%Y-%m-%d_%H%M%S") | KX-Worker VM created by Vagrant" | sudo tee /usr/share/kx.as.code/workspace/gogogo'
        subconfig.trigger.after :destroy do |trigger|
          trigger.warn = "Destroying VM's disks"
          trigger.run = { :inline => "bash -c 'rm -f kx-worker#{i}-local-k8s-storage.vdi'" }
        end
        subconfig.vm.provider "virtualbox" do |v|

          kx_worker_local_k8s_storage = "#{current_dir}/kx-worker#{i}-local-k8s-storage.vdi"
          if ARGV[0] == "up" && ! File.exist?(kx_worker_local_k8s_storage)
            v.customize [
              'createhd',
              '--filename', kx_worker_local_k8s_storage,
              '--format', 'VDI',
               '--size', LOCAL_KUBE_VOLUMES_DISK_SIZE * 1024
            ]

            v.customize [
              'storageattach', :id,
              '--storagectl', 'SATA Controller',
              '--port', 1, '--device', 0,
              '--type', 'hdd', '--medium',
              kx_worker_local_k8s_storage
            ]
          end

          v.name = "kx.as.code-#{ENVIRONMENT_PREFIX}-worker#{i}-#{BOX_VERSION}"
          v.customize ["modifyvm", :id, "--memory", "#{WORKER_NODE_MEMORY}"]
          v.customize ["modifyvm", :id, "--cpus", "#{WORKER_NODE_CPU_CORES}"]
          v.customize ["modifyvm", :id, "--nic1", "nat"]
          v.customize ["modifyvm", :id, "--nic2", "natnetwork","--natnetwork1","kxascode"]
        end
      end
    end

end
